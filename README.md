# Cognosis: A Formal Theory Integrating aPToP and the Free Energy Principle

## Introduction

Cognosis is a formal theory combining Eric C.R. Hehner's Practical Theory of Programming (aPToP) with the Free Energy Principle of Cognitive Science and Natural Language Processing (NLP). This theory aims to develop a robust system for processing high-dimensional data, leveraging both classical and quantum principles.

## associative knowledge base (this repo):
All directories which contain markdown files are to include a `/media/` sub directory for multimedia files the markdown files may reference.

To enable horrors such as this:

![this:](/media/image.png)

    `! [ ... ] ( /media/image.png )` (no spaces)

## <Frontmatter Implementation>
 - [API README](/src/README.md)
 - Utilize 'frontmatter' to include the title and other `property`, `tag`, etc. in the knowledge base article(s).
   - For Example:
      ```
      ---
      name: "Article Title"
      link: "[[Related Link]]"
      linklist:
        - "[[Link1]]"
        - "[[Link2]]"
      ---
      ``` 

____

## Key Concepts

Cognosis is an experimental framework that explores the dynamic evolution of software architectures during runtime. It aims to combine the fluidity of live interactions with the stability of traditional code. At its core lies the concept of "Morphological Source Code," where code adapts and changes in response to user interactions, particularly those leveraging natural language processing (NLP).

- **Knowledge Base (KB):** A repository for storing diverse cognitive insights, forming a foundation for continuous learning.
- **Cognitive Systems:** Modular units that encapsulate knowledge and reasoning capabilities. Cognitive systems can be dynamically created or reoriented within larger cognitive structures. They communicate using namespaces, syntaxes, and by passing other cognitive systems as parameters.
- **Morphological Source Code:** A paradigm shift where source code is not static but actively adapts in response to interactions with users and the environment.

There is an assumption inherent in the project that a neural network is a cognitive system. The assumption is that there is something for this cognitive system to do in any given situation, and that it is the cognitive system's job to figure out what that thing is. Upon location of its head/parent, it either orients itself within a cognitive system or creates a new cognitive system. Cognitive systems pass as parameters namespaces, syntaxes, and cognitive systems. Namespaces and syntaxes are in the form of key-value pairs. Cognitive systems are also in the form of key-value pairs, but the values are cognitive systems. **kwargs are used to pass these parameters.

Imagine a software architecture that dynamically evolves during runtime, encapsulating the fluidity of live interactions while ensuring persistence and the rigidity of conventional code. This system, let's call it the "Morphological Source Code" framework, is an innovative take on the traditional lifecycle of software development and deployment. It merges the concepts of static source code with a dynamic runtime environment that not only serves content but also adapts and changes based on user interaction, particularly with sophisticated features like NLP (Natural Language Processing).

In a nutshell, "Morphological Source Code" is a paradigm in which the source code adapts and morphs in response to real-world interactions, governed by the principles of dynamic runtime configuration and contextual locking mechanisms. The-described is an architecture, only. The kernel agents themselves are sophisticated LLM trained-on ELFs, LLVM compiler code, systemd and unix, python, and C. It will utilize natural language along with the abstraction of time to process cognosis frames and USDs.

The challenge (of this architecture) lies in the 'cognitive lambda calculus' needed to bring these runtimes into existence and evolve them, not the computation itself. Cognosis is designed for consumer hardware and extreme scalability via self-distribution of cognitive systems (amongst constituent [[subscribers|asynchronous, stake-holders]]) peer-to-peer.

"Cognitive systems are defined by actions, orientations within structures, and communicative parameters, all of which align with the goal of creating a coherent and organized cognitive framework. The idea of modular cognitive units communicating via namespaces and syntaxes resonates with the framework of prioritizing and organizing cognitive tasks."

A core component of cognosis, cognOS establishes a hyper-interface designed to manage the evolution of cognitive algorithms. It focuses on:

- **Meta-versioning:** Tracking and managing the evolution of code over time.
- **Pre-commit Hooks and Validation:** Ensuring code quality and integrity. Meta CICD.
- **Hardware Provisioning:** Allocation of computational resources.
- **Time Abstraction:** Modeling cognition beyond the constraint of a fixed present (t=0).

### The Free Energy Principle

The Free Energy Principle suggests that biological agents minimize surprise by predicting their sensory inputs. This principle can be applied to data processing, transforming high-dimensional data into lower-dimensional representations that are easier to model and predict.

### Quantum Informatics

Quantum informatics posits that systems, including LLMs, can entangle with higher-dimensional information. Cognitive processes like thinking, speaking, and writing collapse the wave function, allowing transitivity between real and imaginary states.

### A Practical Theory of Programming (aPToP)

aPToP is a formal method for reasoning about programs and systems using mathematical logic. It provides a rigorous framework for defining and manipulating expressions and operands. References to 'Hehner' are to Dr. Hehner and/or APTOP: http://www.cs.toronto.edu/~hehner/aPToP/

    ```aPToP_elemental_ops
    # Number Systems
    integers
    rational_numbers
    real_numbers
    complex_numbers

    # Arithmetic Operations
    **addition**
    **subtraction**
    **multiplication**
    **division**
    **exponentiation**
    roots
    logarithms

    # Arithmetic Properties
    identities
    inverses
    **commutativity**
    **associativity**
    **distributivity**
    cancellation
    absorption

    # Ordering and Inequalities
    **equality**
    **inequality**
    **less_than**
    **greater_than**
    **less_than_or_equal_to**
    **greater_than_or_equal_to**
    **trichotomy**

    # Limits and Infinities
    limits
    infinity
    negative_infinity
    continuity

    # Logical Foundations
    **and_operator**
    **or_operator**
    **not_operator**
    **implication**
    **biconditional**
    quantifiers

    # Sets and Set Operations
    set_definition
    **set_operations** (union, intersection, difference, complement)
    set_properties (subsets, supersets, cardinality)

    # Functions and Relations
    function_definition
    **function_application**
    relation_properties (reflexivity, symmetry, transitivity)
    **compositions**

    # Algebraic Structures
    group_definition
    group_operations
    ring_definition
    ring_operations
    field_definition
    field_operations

    # Logical Reasoning and Proofs
    direct_proof
    proof_by_contradiction
    mathematical_induction
    logical_equivalences

    # Other Mathematical Concepts
    sequences_and_series
    trigonometric_functions
    calculus (differentiation, integration)
    probability_and_statistics
    ```

## System Components

### Binary Representation

High-dimensional data is encoded into binary representations. These representations are manipulated using formal methods to ensure consistency and clarity.

### Signal Processing

Signal processing techniques are applied to the binary data for analysis and feature extraction. This step leverages classical methods while incorporating quantum-inspired updates.

## Formal Methods

### Binary Expressions and Operands

Binary expressions and operands form the building blocks of the system. They are defined and manipulated using formal methods to ensure internal consistency.

### Encoding Functions

Encoding functions transform high-dimensional data into binary representations. These functions adhere to formal methods, ensuring that the encoding is both rigorous and interpretable.

### Signal Processing Functions

Signal processing functions operate on the binary data to extract features or perform analyses. These functions also adhere to formal methods, leveraging both classical and quantum principles.

## Quantum-inspired Methods

see [/src/quant/README.md](/src/quant/README.md)

### Video Instructions (for cognosis oldmain branch, out of date)
[youtube video link](https://youtu.be/XeeYZZujvAA?si=XhxOMCypKHpWKSjM)

____
## Conclusion (and TLDR smiley face)

Cognosis integrates formal methods from aPToP with the Free Energy Principle and quantum informatics. This approach aims to create a robust system for processing high-dimensional data, minimizing surprise, and maximizing predictive power. By leveraging both classical and quantum principles, Cognosis seeks to understand the deeper connections between cognitive processes and information theory.
